{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5001bb93",
   "metadata": {},
   "source": [
    "# 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f54766c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library load\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3454c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = 50000     # 초기값 50000, 고정\n",
    "#print(MAX_SAMPLES)\n",
    "\n",
    "BATCH_SIZE = 64          # 64\n",
    "BUFFER_SIZE = 20000      # 20000\n",
    "\n",
    "\n",
    "# 모델 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수 ,2\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원,256\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 ,8\n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기 , 512\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율 , 0.1\n",
    "\n",
    "beta_1=0.9\n",
    "beta_2=0.98\n",
    "epsilon=1e-9\n",
    "\n",
    "EPOCHS = 20   # 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa5e8c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path_to_zip = tf.keras.utils.get_file(\n",
    "#    'cornell_movie_dialogs.zip',\n",
    "#    origin='http://www.cs.cornell.edu/~cristian/data/cornell_movie_dialogs_corpus.zip',\n",
    "#    extract=True)\n",
    "\n",
    "path_to_dataset = r'C:\\Users\\user\\Google 드라이브\\AIFFEL\\Day34\\ChatbotData.csv'\n",
    "#os.path.join(os.path.dirname(path_to_zip), \"cornell movie-dialogs corpus\")\n",
    "\n",
    "#path_to_movie_lines = os.path.join(path_to_dataset, 'movie_lines.txt')\n",
    "#path_to_movie_conversations = os.path.join(path_to_dataset,'movie_conversations.txt')\n",
    "\n",
    "cbdata = pd.read_csv(path_to_dataset)\n",
    "cbdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fddca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     12시 땡!\n",
       "1                1지망 학교 떨어졌어\n",
       "2               3박4일 놀러가고 싶다\n",
       "3            3박4일 정도 놀러가고 싶다\n",
       "4                    PPL 심하네\n",
       "5                  SD카드 망가졌어\n",
       "6                    SD카드 안돼\n",
       "7             SNS 맞팔 왜 안하지ㅠㅠ\n",
       "8    SNS 시간낭비인 거 아는데 매일 하는 중\n",
       "9          SNS 시간낭비인데 자꾸 보게됨\n",
       "Name: Q, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = cbdata.iloc[:,0]\n",
    "questions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6d72f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            하루가 또 가네요.\n",
       "1             위로해 드립니다.\n",
       "2           여행은 언제나 좋죠.\n",
       "3           여행은 언제나 좋죠.\n",
       "4            눈살이 찌푸려지죠.\n",
       "5    다시 새로 사는 게 마음 편해요.\n",
       "6    다시 새로 사는 게 마음 편해요.\n",
       "7      잘 모르고 있을 수도 있어요.\n",
       "8         시간을 정하고 해보세요.\n",
       "9         시간을 정하고 해보세요.\n",
       "Name: A, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = cbdata.iloc[:,1]\n",
    "answers[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a874aa6",
   "metadata": {},
   "source": [
    "# 2. 데이터 전처리하기\n",
    "- 영어 데이터와는 전혀 다른 데이터인만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941f909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 로드하고 전처리하여 질문을 questions, 답변을 answers에 저장합니다.\n",
    "#questions, answers = load_conversations()\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "VOCAB_SIZE = len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee7cb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 8552번째 질문 샘플: 헤어지는거 잘하는사람들 부러워\n",
      "전처리 후의 8552번째 답변 샘플: 잘하는 척 하는 사람만 있는 거예요.\n"
     ]
    }
   ],
   "source": [
    "random_number = random.randrange(VOCAB_SIZE)\n",
    "print('전처리 후의 {}번째 질문 샘플: {}'.format(random_number+1, questions[random_number]))\n",
    "print('전처리 후의 {}번째 답변 샘플: {}'.format(random_number+1, answers[random_number]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d90d6",
   "metadata": {},
   "source": [
    "# 3. SubwordTextEncoder 사용하기\n",
    "- 형태소 분석기가 아닌 내부단어 토크나이저인 SubwordTextEncdoer를 그대로 사용."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf0509dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8361]\n",
      "END_TOKEN의 번호 : [8362]\n",
      "8363\n",
      "슝=3\n",
      "정수 인코딩 후의 8552번째 질문 샘플: [3816, 2325, 8168]\n",
      "정수 인코딩 후의 8552번째 답변 샘플: [138, 236, 303, 30, 8151]\n",
      "40\n",
      "슝=3\n",
      "단어장의 크기 : 8363\n",
      "필터링 후의 질문 샘플 개수: 11823\n",
      "필터링 후의 답변 샘플 개수: 11823\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer 선언: SubwordTextEncoder\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)\n",
    "\n",
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])\n",
    "\n",
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)\n",
    "print(\"슝=3\")\n",
    "\n",
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 {}번째 질문 샘플: {}'.format(random_number+1, tokenizer.encode(questions[random_number+1])))\n",
    "print('정수 인코딩 후의 {}번째 답변 샘플: {}'.format(random_number+1, tokenizer.encode(answers[random_number+1])))\n",
    "\n",
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 40\n",
    "print(MAX_LENGTH)\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 40 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n",
    "print(\"슝=3\")\n",
    "\n",
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc586f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88ee1610",
   "metadata": {},
   "source": [
    "# 4. 모델 구성하기\n",
    "- 실습 내용을 참고하여 트랜스포머 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6121ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f897e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b73f9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1ebb1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f19a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99fa0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
    "\n",
    "\n",
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bd5475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n",
    "\n",
    "\n",
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d336b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39f81b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "004b97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d87b2603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f64e98",
   "metadata": {},
   "source": [
    "## (2) 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25f940d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24ebfad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    3195136     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    3722496     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8363)   2149291     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,066,923\n",
      "Trainable params: 9,066,923\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2b6415f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 18s 72ms/step - loss: 1.4633 - accuracy: 0.0208\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 1.1835 - accuracy: 0.0492\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 1.0072 - accuracy: 0.0505\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 14s 73ms/step - loss: 0.9306 - accuracy: 0.0543\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 14s 74ms/step - loss: 0.8714 - accuracy: 0.0576\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 16s 87ms/step - loss: 0.8125 - accuracy: 0.0619\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 16s 84ms/step - loss: 0.7461 - accuracy: 0.0678\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 17s 90ms/step - loss: 0.6740 - accuracy: 0.0756\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 17s 94ms/step - loss: 0.5951 - accuracy: 0.0843\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 25s 133ms/step - loss: 0.5128 - accuracy: 0.0936\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 15s 83ms/step - loss: 0.4294 - accuracy: 0.1038\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 62s 334ms/step - loss: 0.3501 - accuracy: 0.1144\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 15s 82ms/step - loss: 0.2764 - accuracy: 0.1250\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 15s 82ms/step - loss: 0.2103 - accuracy: 0.1353\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 15s 81ms/step - loss: 0.1546 - accuracy: 0.1451\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 15s 80ms/step - loss: 0.1116 - accuracy: 0.1529\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 15s 81ms/step - loss: 0.0825 - accuracy: 0.1582\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 15s 81ms/step - loss: 0.0615 - accuracy: 0.1621\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 15s 81ms/step - loss: 0.0509 - accuracy: 0.1639\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 15s 81ms/step - loss: 0.0458 - accuracy: 0.1646\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=beta_1, beta_2=beta_2, epsilon=epsilon)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b2d4db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 3))\n",
    "#ax = ravel()\n",
    "\n",
    "for i, met in enumerate(['loss', 'accuracy']):\n",
    "    ax[i].plot(history.history[met])\n",
    "    ax[i].set_title('Model {}'.format(met))\n",
    "    ax[i].set_xlabel('epochs')\n",
    "    ax[i].set_ylabel(met)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df377b",
   "metadata": {},
   "source": [
    "# 5. 모델 평가\n",
    "- Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d48d4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0558f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b555f7e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2900/1659896569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentence_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2900/3759274914.py\u001b[0m in \u001b[0;36msentence_generation\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msentence_generation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m   \u001b[1;31m# 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2900/2573678236.py\u001b[0m in \u001b[0;36mdecoder_inference\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecoder_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m   \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;31m# 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2900/3390735027.py\u001b[0m in \u001b[0;36mpreprocess_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;31m# (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[1;31m#sentence = re.sub(r\"[^a-zA-Z?.!,\\u3131-\\u3163\\uac00-\\ud7a3]+\", \" \", sentence)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m   \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"슝=3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "sentence_generation(questions[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation(questions[1060])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f574438",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation(questions[9990])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf52065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation(questions[153])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253eec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_generation(questions[random.randrange(VOCAB_SIZE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21a007",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa3703",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print('총 소요시간은 약 {}분입니다.'.format((end_time-start_time)//60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a07131",
   "metadata": {},
   "source": [
    "# Rubric\n",
    "1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\n",
    "- 공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\n",
    "- 구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "3. 한국어 입력 문장에 대해 한국어로 답변하는 함수를 구현하였다.\n",
    "- 한국어 입력 문장에 그럴듯한 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7603d6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_sentence(sentence):\n",
    "  #sentence = sentence.lower().strip()\n",
    "\n",
    "  # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "  # 예를 들어서 \"I am a student.\" => \"I am a student .\"와 같이\n",
    "  # student와 온점 사이에 거리를 만듭니다.\n",
    "  #sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "  #sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "  #sentence = re.sub(r\"[^a-zA-Z?.!,\\u3131-\\u3163\\uac00-\\ud7a3]+\", \" \", sentence)\n",
    "  sentence = sentence.strip()\n",
    "  return sentence\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5eb6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "# plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "# plt.ylabel(\"Learning Rate\")\n",
    "# plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe515a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations(path_to_dataset):\n",
    "  id2line = {}\n",
    "  with open(path_to_dataset, errors='ignore') as file:\n",
    "    lines = file.readlines()\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    id2line[parts[0]] = parts[4]\n",
    "\n",
    "  inputs, outputs = [], []\n",
    "  with open(path_to_dataset, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "  for line in lines:\n",
    "    parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "    conversation = [line[1:-1] for line in parts[3][1:-1].split(', ')]\n",
    "\n",
    "    for i in range(len(conversation) - 1):\n",
    "      # 전처리 함수를 질문에 해당되는 inputs와 답변에 해당되는 outputs에 적용.\n",
    "      inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "      outputs.append(preprocess_sentence(id2line[conversation[i + 1]]))\n",
    "\n",
    "      if len(inputs) >= MAX_SAMPLES:\n",
    "        return inputs, outputs\n",
    "  return inputs, outputs\n",
    "print(\"슝=3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
